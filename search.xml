<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hexo个人Blog搭建--基础</title>
    <url>/2022/02/16/Hexo%E4%B8%AA%E4%BA%BABlog%E6%90%AD%E5%BB%BA-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><p>推荐使用linux系统</p>
<p>或者在win10操作系统上安装Git，使用Git Bash也可以</p>
<p>在这里我们使用Win10操作系统使用Git Bash来进行操作。</p>
<span id="more"></span>
<p>首先需要会一点git的基础知识,  <a href="https://git-scm.com/">下载git</a></p>
<p><a href="http://nodejs.cn/">下载node.js</a></p>
<p>直接进行默认安装即可</p>
<p>这里贴一下我的版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node.js v16.14</span><br><span class="line">npm 8.3.1</span><br><span class="line">git 2.35.0.windows.1</span><br></pre></td></tr></table></figure>
<h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p>需要借助npm包进行安装。<br>但是在国内安装镜像源很慢，所以使用npm安装cnpm。</p>
<h4 id="安装cnpm"><a href="#安装cnpm" class="headerlink" title="安装cnpm"></a>安装cnpm</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
<p>安装完毕后查看cnpm版本<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cnpm -v</span><br></pre></td></tr></table></figure></p>
<h4 id="安装Hexo框架"><a href="#安装Hexo框架" class="headerlink" title="安装Hexo框架"></a>安装Hexo框架</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>查看是否安装<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure></p>
<h3 id="本地启动Hexo"><a href="#本地启动Hexo" class="headerlink" title="本地启动Hexo"></a>本地启动Hexo</h3><p>选择合适的地方创建blog文件夹，我这里选择的是D盘。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir blog</span><br></pre></td></tr></table></figure><br>进入blog文件夹<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd blog</span><br></pre></td></tr></table></figure><br>初始化一个blog<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure><br>启动blog<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo server 或者 hexo s</span><br></pre></td></tr></table></figure><br>上述步骤无误的话会在https:\\\\localhost:4000<br>查看到Hexo的blog页面，可以看到已经有了内置的helloworld的Hexo博客。</p>
<p>我们也可以创建第一篇博客<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo n &quot;我的第一篇博客文章&quot;</span><br></pre></td></tr></table></figure><br>之后就可以在source/_posts/文件夹查看到md文档。</p>
<p>可以在本地进行编辑md文档，之后可以通过hexo上传blog</p>
<p>接着输入以下指令即可完成本地端Blog的运行。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean # 清理hexo本地缓存</span><br><span class="line">hexo generate/g # 重新生成静态文件</span><br><span class="line">hexo server/s # 启动hexo本地调试</span><br></pre></td></tr></table></figure><br>之后就可以在localhost里看到新博文了。</p>
<h3 id="部署到远端-Github"><a href="#部署到远端-Github" class="headerlink" title="部署到远端(Github)"></a>部署到远端(Github)</h3><h4 id="创建repository"><a href="#创建repository" class="headerlink" title="创建repository"></a>创建repository</h4><p>登录Github</p>
<p>新建一个repository，注意repository name一定要是昵称.github.io</p>
<p>例如我的昵称为<strong>ilingen</strong>, 那么这里repository name为<strong>ilingen.github.io</strong></p>
<p>注意选择public</p>
<p>创建完毕后复制空仓库的git地址。</p>
<h4 id="安装Git部署的插件"><a href="#安装Git部署的插件" class="headerlink" title="安装Git部署的插件"></a>安装Git部署的插件</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cnpm install --save hexo hexo-deployer-git</span><br></pre></td></tr></table></figure>
<p>修改根目录/blog下的<strong>_config.yml</strong>文件</p>
<p>文件最底部修改成</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">	type: git</span><br><span class="line">	repository: https://github.com/github-username/github-username.github.io.git</span><br><span class="line">	branch: main</span><br></pre></td></tr></table></figure>
<p>之后就可以执行上述步骤，部署到远端</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean # 清理hexo本地缓存</span><br><span class="line">hexo generate/g # 重新生成静态文件</span><br><span class="line">hexo server/s # 启动hexo本地调试</span><br><span class="line">hexo deploy/d # 部署到github</span><br></pre></td></tr></table></figure>
<p>输入Github账号密码，完成git部署即可在浏览器查看自己的blog了。</p>
<h3 id="一些总结以及后续的工作"><a href="#一些总结以及后续的工作" class="headerlink" title="一些总结以及后续的工作"></a>一些总结以及后续的工作</h3><p>折腾过来过去, 换了5,6个主题, 一开始用的Maupassant主题, 后来发现版本太老了, 不支持数学公式插件了, 但还是喜欢这种简洁的主题, 所以万般无奈下去官网找了好几个pure主题, 最后还是有各种各样的问题, 最后不想在这上面浪费时间了, 我写blog的初心就是为了记录自己的学习过程, 不是为了搞那种花里胡哨的东西, 所以最后选择使用人数最多的next主题, 最后花了一上午的时间完成了基本配置…</p>
<p>后续博客的升级可能会等到暑假了, 会对blog增加评论</p>
<p>后续主要会在上面发一些学习笔记相关的内容.</p>
]]></content>
      <categories>
        <category>博客站务</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title>关于BM25</title>
    <url>/2022/02/26/%E5%85%B3%E4%BA%8EBM25/</url>
    <content><![CDATA[<h1 id="BM25-Best-Match"><a href="#BM25-Best-Match" class="headerlink" title="BM25(Best Match)"></a>BM25(Best Match)</h1><p>BM25算法是在20世纪70年代到80年代由英国的一批信息检索领域的计算机科学家发明, 用来衡量<strong>搜索词query和文档document相似度得分</strong>的经典算法，这个相关性打分是一个类似TF-IDF的基于统计计数的无监督学习过程.<br><strong>是一种基于词袋方法的词频计数, 它不考虑多个搜索词在文档中的关联性, 只考虑它们各自的出现次数</strong></p>
<span id="more"></span>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h1><p>BM25算法的核心思想可以简介如下: 对query进行特征提取分解, 生成若干特征词<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>, 然后对于每个搜索结果D, 计算每个特征<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>与D的相关性得分, 最后, 将<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>相对于D的相关性得分进行加权求和, 从而得到query与D的相关性得分.</p>
<p>BM25的公式主要由三个部分组成</p>
<ul>
<li><p>query中每个单词<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>与文档d之间的相关性</p>
</li>
<li><p>单词<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>与query之间的相似性</p>
</li>
<li><p>每个单词<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的权重(IDF)</p>
</li>
</ul>
<h1 id="BM25公式"><a href="#BM25公式" class="headerlink" title="BM25公式"></a>BM25公式</h1><script type="math/tex; mode=display">Score(Q, d)= \sum_{i}^n{W_iR(q_i, d)}</script><p>其中Q表示query, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>表示query中的单词. d表示一个搜索文档, </p>
<h2 id="W-i-表示单词权重-IDF"><a href="#W-i-表示单词权重-IDF" class="headerlink" title="$W_i$表示单词权重(IDF)"></a><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.875ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1271 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>表示单词权重(IDF)</h2><p>BM25选择是Robertson-Sparck Jones IDF</p>
<script type="math/tex; mode=display">W_i=IDF(q_i)=log(\frac {N-df_i+0.5}{df_i+0.5})</script><p>其中N表示索引中全部文档数, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="3.025ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 1337 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="msub" transform="translate(520,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>为包含<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的文档的个数. 依据IDF的作用, 对于某个<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>, 包含<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的文档数越多, 说明<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>重要性越小, 或者区分度很低, IDF越小, 因此IDF可以用来刻画<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>与文档的相关性.</p>
<p>这里有个问题, 如果一个词在超过半数的文档里出现, 则IDF为负值, 于是这个词对BM25分数的贡献就是负的. 一般不希望这样的特性, 所以当IDF为负数时, 可将其置为0, 或者一个比较小的正数, 或者改用一个平滑过渡到0的函数形式.</p>
<h2 id="R-q-i-d-表示单词和文档的相关性"><a href="#R-q-i-d-表示单词和文档的相关性" class="headerlink" title="$R(q_i, d)$表示单词和文档的相关性"></a><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="7.409ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3274.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1148,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1921,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2365.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2885.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>表示单词和文档的相关性</h2><p>比较朴素的考虑可以用特征词的文档词频来简单表示<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="7.409ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3274.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1148,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1921,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2365.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2885.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>, 但这种直观的想法不可避免的导致长文本中, 词的频度普遍较高, 最终相关性得分会过度倾向于长文本. 另一方面, 不难想到, 某个词对文档的贡献不应该无限度地随词频增加而线性增加, 当该次的词频高于某个词就应该趋于饱和, 而不应该让其得分贡献度无限度增大, 从而在整个得分求和式子中占支配地位.</p>
<p>BM25的设计依据一个重要的发现: 词频和相关性之间的关系是非线性的, 也就是说, 每个词对于文档的相关性分数不会超过一个特定的阈值, 但词的次数达到一个阈值后, 其影响就不在线性增加了, 而这个阈值和文档本身有关. 因此, 在刻画单词和文件相似性时, BM25是这样设计的.</p>
<script type="math/tex; mode=display">R(q_i, d)=\frac{(k_1+1)tf_{td}}{K+tf_{td}}</script><script type="math/tex; mode=display">K=k_1(1-b+b*\frac{L_d}{L_{ave}})</script><p>其中, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="3.523ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 1557 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="msub" transform="translate(361,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></g></g></svg></mjx-container>是单词t在文档d中的词频, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex" xmlns="http://www.w3.org/2000/svg" width="2.56ex" height="1.901ex" role="img" focusable="false" viewBox="0 -683 1131.7 840.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></g></svg></mjx-container>是文档d的长度, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="4.096ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1810.5 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(529,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(1014,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g></g></g></g></svg></mjx-container>是所有文档的平均长度, </p>
<p>超参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex" xmlns="http://www.w3.org/2000/svg" width="2.166ex" height="1.91ex" role="img" focusable="false" viewBox="0 -694 957.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mn" transform="translate(554,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>起到调节特征词文本频率尺度的作用, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex" xmlns="http://www.w3.org/2000/svg" width="6.315ex" height="1.91ex" role="img" focusable="false" viewBox="0 -694 2791.1 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mn" transform="translate(554,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1235.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2291.1,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container>时算法退化为二元模型(Binary model)(没有词频), 取更大的值使用更原始的词频信息.<br>b一般被称作文本长度的规范化, 是另一个可调参数(<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="9.267ex" height="1.661ex" role="img" focusable="false" viewBox="0 -694 4096.1 734"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mi" transform="translate(1833.6,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(2540.3,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(3596.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>), 是用决定文档长度对相关性影响的大小: 当b为1, 是完全使用文档长度来衡量相关性, 当b=0, 表示不使用文档长度. <strong>可以看出b越大，文档长度对相关性得分的影响越大，反之越小</strong>。而文档d的相对长度越长，K越大，也就是R的分母越大，R相关性得分也就越小。这里可以理解成，当文档较长时，包含的词语也就越多，那么相应地包含有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>这个词的可能性也就越大，但是虽然可能性要大一点，当<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的频率同等的情况下，长文档与qi的相关性就应该比短文档与qi的相关性弱。</p>
<h2 id="单词和query的相关性"><a href="#单词和query的相关性" class="headerlink" title="单词和query的相关性"></a>单词和query的相关性</h2><p>当query很长时, 我们还需要刻画单词和query之间的权重. 对于短的query, 这一项不是必须的</p>
<script type="math/tex; mode=display">R(q_i, Q)=\frac{(k_2+1)tf_{tq}}{k_2+tf_{tq}}</script><p>这里<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="3.523ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 1557 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="msub" transform="translate(361,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></g></g></svg></mjx-container>表示单词t在query中的词频, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex" xmlns="http://www.w3.org/2000/svg" width="2.166ex" height="1.91ex" role="img" focusable="false" viewBox="0 -694 957.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mn" transform="translate(554,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container>是一个可调正参数, 来矫正query中的词频范围.</p>
<h2 id="最终公式"><a href="#最终公式" class="headerlink" title="最终公式"></a>最终公式</h2><script type="math/tex; mode=display">score(q, d)=\sum_{t \in q}[log(\frac {N-df_i+0.5}{df_i+0.5})] \cdot \frac{(k_1+1)tf_{td}}{k_1((1-b)+b(L_d/L_{ave}))+tf_{td}} \cdot \frac {(k_2+1)tf_{tq}}{k_2+tf_{tq}}</script><p>经过试验, 上面三个可调参数, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex" xmlns="http://www.w3.org/2000/svg" width="2.166ex" height="1.91ex" role="img" focusable="false" viewBox="0 -694 957.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mn" transform="translate(554,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex" xmlns="http://www.w3.org/2000/svg" width="2.166ex" height="1.91ex" role="img" focusable="false" viewBox="0 -694 957.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mn" transform="translate(554,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container>可取1.2~2, b取0.75</p>
<p>从以上对 BM25 的完整讨论，我们知道了 BM25 其实是一个（准确说，是一系列）经验公式，这里面的每一个环节都是经过很多研究者的迭代而逐步发现的。很多研究在理论上对 BM25 进行了建模，从“概率相关模型”（Probabilistic Relevance Model）入手，推导出 BM25 其实是对某一类概率相关模型的逼近，对此我还没有详尽研究，就无法进一步展开论述了。从结果上看，我们应该明了 BM25 权重计算公式，已经在众多的数据集和搜索任务上，被极其高频广泛和成功地使用.</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>相对完整的介绍了在IR领域重要的相关性打分算法BM25.后续如果有更深的体会也会进行更新.<br>BM25算法公式由三个主要的模块构成—词在文档中的相关度, 词在查询关键字中的相关度以及词的权重(IDF).</p>
<p>BM25算法是一个长期积累的经验公式, 是一个简单高效基础基于词袋的无监督的learning-to-rank的算法, 但是并没有考虑词之间的相关性, 是在词的基础上进行统计计算, 没有深入到语义层面.</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/geeks-reign/p/Okapi_BM25.html">Okapi BM25算法 - geeks_reign - 博客园</a><br><a href="https://zhuanlan.zhihu.com/p/79202151">BM25算法, Best Matching - 知乎</a><br><a href="https://blog.csdn.net/Tink1995/article/details/104745144">史上最小白之BM25详解与实现_Tink1995的博客-CSDN博客_bm25</a></p>
]]></content>
      <categories>
        <category>知识整理</category>
      </categories>
      <tags>
        <tag>IR</tag>
        <tag>unsupervised learning</tag>
        <tag>learning-to-rank</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentence-BERT论文分享</title>
    <url>/2022/03/02/Sentence-BERT%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p>最近在准备毕设，需要用到Sentence-BERT，所以找来论文进行了一次精读，下面主要为原文翻译和我的一些注释。</p>
<p>原论文链接<a href="https://arxiv.org/abs/1908.10084">在这</a></p>
<p>论文提供的代码<a href="https://github.com/UKPLab/sentence-transformers">在这</a></p>
<span id="more"></span>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>BERT和RoBERTa在语义文本相似性(semantic textual similarity, STS)等句子对(sentence-pair)回归任务上有SOTA的表现。然而，这需要两个句子都输入到网络中，这回造成巨大的计算开销。在10000个句子的集合中找到最相似的句子对需要使用BERT进行大约50000w词推理计算(65小时)。BERT的构造使得它不适合用于语义相似性搜索以及聚类等无监督任务。</p>
<p>我们提出了Sentence-BERT（SBERT），这是对预训练的BERT网络的一种修改，它使用<strong>siamese和triplet(三重网络)结构来推导语义上有意义的句子嵌入，可以使用余弦相似性进行比较。这减少了寻找最相似配对的工作量，从使用BERT/RoBERTa的65小时减少到使用SBERT的约5秒，同时保持了使用BERT的准确性。</strong><br>我们评估了SBERT和SRoBERTa在常见STS任务和迁移学习任务中的表现，其表现优于其他最先进的句子嵌入方法。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Sentence-BERT时对BERT网络的一种修改，使用siamese和三元组网络(triplet networks)，能够导出语义上有意义的句子嵌入(sentence-embedding)。</p>
<blockquote>
<p> 这里的<strong>句子嵌入是指语义上相似的句子在向量空间相近。和word-embedding类似。</strong></p>
</blockquote>
<p>这使得SBERT能够用于某些新任务，这些任务到现在为止还不适用于BERT。包含<strong>大规模的语义相似性对比，聚类和通过语义搜索进行信息检索。</strong></p>
<p>BERT在各种句子分类和句子对回归任务上取得了SOTA的表现。</p>
<p><strong>BERT使用交叉编码器(cross-encoder)：将两句话传递transformer网络并且预测目标值。然而，由于可能的组合太多，这些设置不适合各种成对回归任务(various pair regression)。</strong></p>
<blockquote>
<p>BERT只接受两个句子的输入，而且每次需要经过BERT内部网络运算后才能得到相似度，所以对于大型任务，开销很大</p>
</blockquote>
<p>在n=10000的句子的集合中，找到最相似的句子需要BERT进行$n·(n-1)/2=49995000$次推理计算。需要大约65h，在modern V100 GPU上。</p>
<p>研究聚类和语义搜索问题的一种常见方法是将每个句子映射到向量空间，这样语义相似的句子就很接近了。<strong>研究人员已经开始在BERT中输入单个句子，并衍生固定大小的句子嵌入。最常用的方法平均BERT输出层(BERT 嵌入)或使用第一个[CLS] token的输出。但是这种常见的作法会产生相当糟糕的句子嵌入，比[[GLoVe]]的嵌入更糟糕。</strong></p>
<p>为了缓解这个问题，我们开发了SBERT, (siamese network)暹罗网络体系结构使输入句子的固定大小向量可以被导出。使用相似性度量，如余弦相似性或曼哈登/欧氏距离，可以找到语义相似的句子。这些相似性度量可以在现代硬件上非常高效地执行，从而允许SBERT用于语义相似性搜索以及聚类。<br>我们在NLI数据集上对SBERT进行微调，SBERT在STS任务上性能提升显著。</p>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>BERT是一个经过预训练的transformer网络，它为各种NLP任务设定了最新的SOTA结果，包括问答(question answering)、句子分类(sentence classification)和句子对回归(sentence-pair regression)。<br>用于句子对回归的BERT输入由两个句子组成，由一个特殊的[SEP]标记分隔。应用超过12层（基本模型）或24层（大模型）的多头注意力机制，并将输出传递到一个简单的回归函数，以导出最终标签。在STS任务上取得了SOTA的结构(Cer,2017)<br>RoBERTa表明，通过对训练前进行一些小的调整，可以进一步题高BERT的表现(Liu 2019)。</p>
<p><strong>BERT网络结构的一个大缺点是没有计算独立的句子嵌入，这使得从BERT导出句子嵌入变得困难。</strong><br>为了绕过这个限制，研究人员通过BERT传递单个句子，然后通过平均输出(类似于平均单词嵌入)或使用特殊CLS标记的输出，得到一个固定大小的向量。(May,zhang,Qiao)<br>这两个选项也由bert-as-a-service-repository提供，但是据我们所知，目前还没有评估这些方法能否产生有用的句子嵌入。</p>
<p>句子嵌入是一个被广泛研究的领域，提出了几十种方法。<br>Skip-Thought训练一种编码器-解码器架构来预测周围的句子。<br>InferSent使用SNLI斯坦福自然语言推理数据集合多类型NLI数据集的标记数据来训练孪生BiLSTM网络，在输出上进行最大池化。优于SkipThought等无监督方法。<br>Universal Sentence Encoder训练一个transformer的网络，并通过SNLI训练增强无监督学习。<br>Hill等人表明，句子嵌入训练的任务显著影响他们的质量。<br>之前的研究发现SNLI数据集适合训练句子嵌入。<br>Yang等人提出了一种使用孪生DAN和孪生transformer网络，从Reddit上进行对话训练，该方法在STS基准数据集上取得了良好的效果。<br>Humeau讨论了BERT的交叉编码器的运行是开销，并提出了一种方法(poly-encoders，多编码器)来计算m个上下文向量和预先计算的候选嵌入之间的分数。这个方法适合在更大的集合中找到得分更高的句子。然而，多编码器的缺点是得分函数不对称，并且计算开销对于聚类等用例来说太大，需要$O(n^2)$得分计算。</p>
<p>以前的神经网络句子嵌入方法是从随机初始化开始训练的。<br>在本论文中，<strong>我们使用预先训练的BERT和RoBERTa网络，并仅对其做微调，以生成有用的句子嵌入</strong>，这大大减少了所需的训练时间。<br>SBERT可以在不到20分钟内调整，同时比类似的句子嵌入方法产生更好的效果。</p>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>SBERT在BERT/RoBERTa的输出中添加了一个池化操作，以导出固定大小的句子嵌入。我们实现了三种池化策略：<strong>使用CLS-token的输出，计算所有输出向量的平均值(MEAN-strategy)，计算输出向量随时间的最大值(MAX-strategy)。默认配置是MEAN。</strong></p>
<p>为了优化BERT/RoBERTa，我们创建了孪生网络和三元组网络(schroff)，以更新权重，从而使生成的句子嵌入具有语义信息，并且可以通过余弦相似性进行比较。</p>
<blockquote>
<p>BERT产生的句向量不能通过余弦相似性比较，余弦相似性默认所有维度的权重是一样的，而BERT的语句嵌入在不同维度上的权重不同。</p>
</blockquote>
<p>我们在以下架构和目标函数进行实验。</p>
<ul>
<li><strong>Classification Objective Function</strong><br>我们把sentence embeddings u和v以及其元素差(element-wise difference)|u-v|进行连接，并将其与可训练的权重$W_t \in R^{3n \times k}$<script type="math/tex; mode=display">o=softmax(W_t(u, v, |u-v|)</script>n是sentence embedding的问题，k是标签的数量。<br>使用交叉熵作为优化。</li>
<li><strong>Regression Objective Function</strong><br>计算sentence embeddings u和v的余弦相似性，我们使用均方误差损失作为目标函数。</li>
<li><strong>Triplet Objective Function</strong><br>给定一个锚定句a，一个正样本p和一个负样本n，Triplet损失调整网络，使得a和p之间的距离小于a和n之间的距离。<br>最小化以下损失函数<script type="math/tex; mode=display">max(||s_a-s_p||-||s_a-s_n||+\epsilon, 0)</script>$s_x$是a,n,p的sentence embedding，|| · ||为距离度量和margin ε。<br>Margin ε确保$s_p$和$s_a$之间的距离要比$s_n$和$s_a$的距离至少近ε。<br>我们使用欧氏距离作为距离度量并且设置ε=1。<br><img src="https://s2.loli.net/2022/03/02/g45s1xCRrLQDIXn.png" alt=""><h2 id="Training-Details"><a href="#Training-Details" class="headerlink" title="Training Details"></a>Training Details</h2>我们在 <strong>SNLI (Bowman et al., 2015) 和 Multi-Genre NLI (Williams et al., 2018) 数据集的组合上训练 SBERT。</strong> SNLI 是 570,000 个句子对的集合，标注了矛盾、eintailment 和中性标签。 MultiNLI 包含 430,000 个句子对，涵盖了各种类型的口语和书面文本。 我们使用一个 epoch 的 3 路 softmaxclassifier 目标函数对 SBERT 进行微调。 我们使用了 16 的批量大小、学习率为 2e-5 的 Adam 优化器，以及超过 10% 的训练数据的线性学习率热身。 我们的默认池化策略是 MEAN。<h1 id="Evaluation-Semantic-Textual-Similarity"><a href="#Evaluation-Semantic-Textual-Similarity" class="headerlink" title="Evaluation-Semantic Textual Similarity"></a>Evaluation-Semantic Textual Similarity</h1></li>
</ul>
<p>我们评估 SBERT 在常见语义文本相似性 (STS) 任务中的性能。<strong>最先进的方法通常会学习一个（复杂的）回归函数，将sentence embedings映射到相似性分数。</strong> 然而，这些回归函数是work pair-wise的，并且由于组合爆炸，如果句子的集合达到一定的大小，这些回归函数通常是不可扩展的。 相反，<strong>我们总是使用余弦相似度来比较两个句子嵌入之间的相似度。 我们还使用负曼哈顿距离和负欧几里德距离作为相似性度量进行了实验，但所有方法的结果大致相同</strong>。</p>
<blockquote>
<p>作者提出的SBERT的语句嵌入可以通过余弦相似度进行比较，从而不需要一个回归函数将embeddings映射到分数上去。</p>
</blockquote>
<h2 id="Unsupervised-STS"><a href="#Unsupervised-STS" class="headerlink" title="Unsupervised STS"></a>Unsupervised STS</h2><p>我们在<strong>不使用任何 STS 特定训练数据的情况下直接评估 SBERT 对 STS 的性能</strong>。 我们使用 STS 任务 2012 - 2016（Agirre et al., 2012, 2013, 2014, 2015, 2016）、STS 基准（Cer et al., 2017）和 SICK-Relatedness 数据集（Marelli et al., 2014） ）。 这些数据集在句子对的语义相关性上提供了 0 到 5 之间的标签。 我们在 (Reimers et al., 2016) 中表明 Pearson 相关性非常适合 STS。 相反，我们计算句子嵌入的余弦相似度与gold标签之间的 Spearman 等级相关性。 其他句子嵌入方法的设置是等效的，相似度由余弦相似度计算。 结果如表 1 所示。<br><img src="https://s2.loli.net/2022/03/02/9PGDo86ihdYaEOq.png" alt=""><br>结果表明，直接使用BERT的输出会导致相当差的性能，平均BERT embedding嵌入实现的平均相关性仅为54.81，使用CLS  token输出为29.19的平均相关性，两者都比计算平均GloVe嵌入差。<br>使用所描述的孪生网络结构和微调机制显著改善了相关性，大大优于InferSent和通Universal Sentence Encoder。SBERT的表现比Universal Sentence Encoder差的唯一数据集是SICK-R。Universal Sentence Encoder在各种数据集上接受过培训，包括新闻、问答页面和论坛，这似乎更适合SICK-R的数据。相比之下，SBERT只在维基百科（通过BERT)和NLI数据上接受过预训练。<br>虽然RoBERTa能够提高多个监督任务的性能，当我们只观察到SBERT和SRoBERTa在生成句子嵌入方面的微小差异。</p>
<h2 id="Supervised-STS"><a href="#Supervised-STS" class="headerlink" title="Supervised STS"></a>Supervised STS</h2><p>STS 基准 (STSb)（Cer 等人，2017 年）提供了一个流行的数据集，用于评估受监督的 STS 系统。数据包括来自标题、新闻和论坛三个类别的 8,628 个句子对。它分为训练（5,749）、开发（1,500）和测试（1,379）。 BERT 通过将两个句子传递到网络并使用简单的回归方法输出，在这个数据集上设置了一个新的最先进的性能。<br>我们<strong>使用训练集和回归目标函数对 SBERT 进行微调。在预测时，我们计算句子嵌入之间的余弦相似度</strong>。所有系统都使用 10 个随机种子进行训练以对抗差异（Reimers 和 Gurevych，2018 年）。<br>结果如表 2 所示。我们试验了两种设置：仅在 STSb 上训练；首先在 NLI 上训练，然后在 STSb 上训练。我们观察到后面的策略导致 1-2 点的轻微改善。这种两步法对BERT交叉编码器的影响特别大，性能提高了3-4个百分点。我们没有观察到 BERT 和 RoBERTa 之间的显著差异。<br><img src="https://s2.loli.net/2022/03/02/6Zb2kWGjYNu1DgQ.png" style="zoom:50%;" /></p>
<h2 id="Argument-Facet-Similarity-AFS语料库"><a href="#Argument-Facet-Similarity-AFS语料库" class="headerlink" title="Argument Facet Similarity (AFS语料库)"></a>Argument Facet Similarity (AFS语料库)</h2><p>我们在 Misra 等人的 Argument Facet Similarity (AFS) 语料库上评估 SBERT。 (2016)。 AFS 语料库注释了来自社交媒体对话的 6,000 个句子论据对，涉及三个有争议的话题：枪支管制、同性婚姻和死刑。数据的注释范围从 0（“不同主题”）到 5（“完全等效”）。 AFS 语料库中的相似性概念与来自 SemEval 的 STS 数据集中的相似性概念完全不同。 <strong>STS 数据通常是描述性的，而 AFS 数据是来自对话的争论性摘录。要被认为是相似的，论证不仅必须提出相似的主张，而且还必须提供相似的推理。</strong>此外，AFS 中句子之间的词汇差距要大得多。因此，简单的无监督方法以及最先进的 STS 系统在该数据集上表现不佳（Reimers 等，2019）。  </p>
<p>我们在两种情况下在此数据集上评估 SBERT：1) 正如 Misra 等人提出的那样，我们使用 10 折交叉验证评估 SBERT。这种评估设置的一个缺点是不清楚方法对不同主题的泛化程度。因此，2）我们在跨主题设置中评估 SBERT。两个主题用于训练，该方法在被遗漏的主题上进行评估。我们对所有三个主题重复此操作并平均结果。</p>
<p>SBERT 使用回归目标函数进行了微调。相似度分数是基于句子嵌入使用余弦相似度计算的。我们还提供了 Pearson 相关性 r 以使结果与 Misra 等人的结果相当。然而，我们表明（Reimers 等人，2016 年）Pearson 相关有一些严重的缺点，在比较 STS 系统时应该避免。结果如表 3 所示。<br><img src="https://s2.loli.net/2022/03/02/1E8ezr2Jt3N4IkY.png" style="zoom:50%;" /><br>tf-idf、平均 GloVe 嵌入或 InferSent 等无监督方法在此数据集上的表现相当糟糕，得分较低。在 10 折交叉验证设置中训练 SBERT 的性能几乎与 BERT 相当。</p>
<p>然而，在跨主题评估中，我们观察到 SBERT 的性能下降了大约 7 个点的 Spearman 相关性。要被视为相似，论点应针对相同的主张并提供相同的推理。 <strong>BERT 能够使用注意力直接比较两个句子（例如逐字比较），而 SBERT 必须将单个句子从一个看不见的主题映射到一个向量空间，以便具有相似主张和原因的论点接近。这是一项更具挑战性的任务，它似乎需要不止两个主题来训练才能与 BERT 相提并论。</strong></p>
<h2 id="Wikipedia-Sections-Distinction"><a href="#Wikipedia-Sections-Distinction" class="headerlink" title="Wikipedia Sections Distinction"></a>Wikipedia Sections Distinction</h2><p>多尔等人 (2018) 使用维基百科为句子嵌入方法创建了一个主题细粒度的训练、开发和测试集。维基百科文章被分成不同的部分，侧重于某些方面。多尔等人假设同一部分中的句子在主题上比不同部分中的句子更接近。他们使用它来创建一个包含弱标记句子三元组的大型数据集：锚点和正例来自同一部分，而反例来自同一文章的不同部分。比如来自 Alice Arnold 的文章：Anchor：Arnold 于 1988 年加入 BBC Radio Drama 公司，正面：Arnold 于 2012 年 5 月获得媒体关注，负面：Balding 和 Arnold 都是狂热的业余高尔夫球手。<br>我们使用 Dor 等人的数据集。我们使用三元组目标，在大约 180 万个训练三元组上训练 SBERT 一个epoch，并在 222,957 个测试三元组上对其进行评估。测试三元组来自一组不同的维基百科文章。作为评估指标，<strong>我们使用准确性：正例是否比负例更接近锚点？</strong>结果如表 4 所示。<br><img src="https://s2.loli.net/2022/03/02/CwYXkEKrP8D4Ni1.png" style="zoom:50%;" /><br>多尔等人使用三元组损失对 BiLSTM 架构进行了微调，以获得该数据集的句子嵌入。如表所示，SBERT 明显优于多尔等人的 BiLSTM 方法。</p>
<h1 id="Evaluation-SentEval"><a href="#Evaluation-SentEval" class="headerlink" title="Evaluation-SentEval"></a>Evaluation-SentEval</h1><p>SentEval (Conneau and Kiela, 2018) 是一种流行的工具包，用于评估句子嵌入的质量。 句子嵌入用作逻辑回归分类器的特征。 逻辑回归分类器在 10 折交叉验证设置中针对各种任务进行训练，并为测试折计算预测精度。<br><strong>SBERT 句子嵌入的目的不是用于其他任务的迁移学习。</strong>在这里，我们认为按照 Devlin 等人的描述对 BERT 进行微调。 （2018）对于新任务是更合适的方法，因为它更新了 BERT 网络的所有层。然而，SentEval 仍然可以给我们在各种任务中的句子嵌入的质量留下印象。<br>我们在以下七个 SentEval 传输任务中将 SBERT 句子嵌入与其他句子嵌入方法进行了比较：<br>• MR：电影评论片段的情感预测，从五个开始（Pang 和 Lee，2005 年）。 • CR：客户产品评论的情绪预测（Hu and Liu，2004）。 • SUBJ：来自电影评论和情节摘要的句子的主观预测（Pang 和 Lee，2004 年）。 • MPQA：来自新闻专线的短语级别意见极性分类（Wiebe 等，2005）。 • SST：带有二元标签的斯坦福情绪树库（Socher 等人，2013 年）。 • TREC：来自TREC 的细粒度问题类型分类（Li 和Roth，2002 年）。 • MRPC：来自平行新闻来源的微软研究释义语料库（Dolan 等，2004）。<br><img src="https://s2.loli.net/2022/03/02/pkoXxtwjsfAR1rU.png" alt=""><br>结果见表 5。SBERT 能够在 7 个任务中的 5 个任务中取得最佳性能。与 InferSent 和 Universal Sentence Encoder 相比，平均性能提高了大约 2 个百分点。尽管迁移学习不是 SBERT 的目的，但它在此任务上优于其他最先进的句子嵌入方法。</p>
<p>SBERT 的句子嵌入似乎很好地捕获了情感信息：与 InferSent 和 Universal Sentence Encoder 相比，我们观察到 SentEval 的所有情感任务（MR、CR 和 SST）都有很大的改进。<br>SBERT 明显比通用句子编码器差的唯一数据集是 TREC 数据集。 Universal Sentence Encoder 在问答数据上进行了预训练，这似乎有利于 TREC 数据集的问题类型分类任务。<br>平均 BERT 嵌入或使用来自 BERT 网络的 CLStoken 输出在各种 STS 任务中取得了糟糕的结果（表 1），比平均 GloVe 嵌入差。然而，对于 SentEval，平均 BERT 嵌入和 BERT CLS token输出取得了不错的结果（表 5），优于平均 GloVe 嵌入。原因是不同的设置。<strong>对于 STS 任务，我们使用余弦相似度来估计句子嵌入之间的相似度。余弦相似性平等对待所有维度。相比之下，SentEval 将逻辑回归分类器拟合到句子嵌入中。这允许某些维度对分类结果具有更高或更低的影响。</strong><br>我们得出的结论是，<strong>来自 BERT 的平均 BERT 嵌入/CLS-token 输出返回的句子嵌入不能与余弦相似度或曼哈顿/欧几里得距离一起使用。</strong><br>对于迁移学习，它们产生的结果比 InferSent 或 Universal Sentence Encoder 稍差。然而，在 NLI 数据集上使用具有 siamese 网络结构的所述微调设置产生句子嵌入，实现了 SentEval 工具包的最新技术水平。</p>
<h1 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h1><p>我们已经证明了 SBERT 句子嵌入质量。 在本节中，我们对 SBERT 的不同方面进行了消融研究，以便更好地了解它们的相对重要性。</p>
<p><strong>我们评估了不同的池化策略（MEAN、MAX 和 CLS）。 对于分类目标函数，我们评估不同的连接方法。</strong> 对于每种可能的配置，我们用 10 个不同的随机种子训练 SBERT 并平均性能。</p>
<p>目标函数（分类与回归）取决于带注释的数据集。 对于分类目标函数，我们在 SNLI 和 Multi-NLI 数据集上训练 SBERTbase。 对于回归目标函数，我们在 STS 基准数据集的训练集上进行训练。 性能是根据 STS 基准数据集的开发拆分来衡量的。 结果如表 6 所示。<br><img src="https://s2.loli.net/2022/03/02/6MTHlbmqCdeRQyK.png" style="zoom:50%;" /><br>在 NLI 数据上使用分类目标函数进行训练时，池化策略的影响相当小。连接模式的影响要大得多。 InferSent (Conneau et al., 2017) 和 Universal Sentence Encoder (Cer et al., 2018) 都使用 (u, v, |u − v|, u ∗ v) 作为 softmax 分类器的输入。然而，在我们的架构中，添加元素 u ∗ v 会降低性能。</p>
<p><strong>最重要的部分是元素差异|u - v|。请注意，连接模式仅与训练 softmax 分类器相关。在推理时，在预测 STS 基准数据集的相似性时，只有句子嵌入 u 和 v 与余弦相似性结合使用。元素差异测量两个句子嵌入维度之间的距离，确保相似对更近，不同对更远。</strong></p>
<p>当用回归目标函数训练时，我们观察到池化策略有很大的影响。在那里，MAX 策略的表现明显比 MEAN 或 CLS 令牌策略差。这与 (Conneau et al., 2017) 形成对比，后者发现 InferSent 的 BiLSTM 层使用 MAX 而不是 MEAN 池化是有益的。</p>
<h1 id="Computational-Efficiency"><a href="#Computational-Efficiency" class="headerlink" title="Computational Efficiency"></a>Computational Efficiency</h1><p>句子嵌入可能需要计算数百万个句子，因此需要高计算速度。在本节中，我们将 SBERT 与平均 GloVe 嵌入、InferSent（Conneau 等人，2017 年）和 Universal Sentence Encoder（Cer 等人，2018 年）进行比较。</p>
<p>为了进行比较，我们使用 STS 基准测试中的句子（Cer 等人，2017 年）。我们使用带有 Python 字典查找和 NumPy 的简单 for 循环来计算平均 GloVe 嵌入。 InferSent4 基于 PyTorch。对于通用句子编码器，我们使用基于 TensorFlow 的 TensorFlow Hub version5。 SBERT 基于 PyTorch。为了改进句子嵌入的计算，我们实施了一种智能批处理策略：将长度相似的句子组合在一起，并仅填充到小批量中最长的元素。这大大减少了填充令牌的计算开销。</p>
<p>性能是在配备 Intel i7-5820K CPU @ 3.30GHz、Nvidia Tesla V100 GPU、CUDA 9.2 和 cuDNN 的服务器上测量的。结果如表 7 所示。<br><img src="https://s2.loli.net/2022/03/02/dC9VXthcNMZiu2q.png" alt=""><br>在 CPU 上，InferSent 比 SBERT 快 65%。 这是由于更简单的网络架构。 InferSent 使用单个 BiLSTM 层，而 BERT 使用 12 个堆叠的 Transformer 层。 然而，transformer 网络的一个优势是 GPU 上的计算效率。 在那里，具有智能批处理的 SBERT 比 InferSent 快约 9%，比 Universal Sentence Encoder 快约 55%。 智能批处理在 CPU 上实现了 89% 的加速，在 GPU 上实现了 48% 的加速。 平均手套嵌入显然是计算句子嵌入的最快方法。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>我们展示了 BERT 开箱即用地将句子映射到一个向量空间，该空间非常不适合与常见的相似性度量（如余弦相似性）一起使用。七个 STS 任务的性能低于平均 GloVe 嵌入的性能。</p>
<p>为了克服这个缺点，我们提出了 Sentence-BERT (SBERT)。 SBERT 在 siamese/triplet 网络架构中对 BERT 进行微调。我们评估了各种常见基准的质量，在那里它可以实现对最先进的句子嵌入方法的显著改进。在我们的实验中，用 RoBERTa 替换 BERT 并没有产生显著的改进。</p>
<p>SBERT 在计算上是高效的。在 GPU 上，它比 InferSent 快约 9%，比 Universal Sentence Encoder 快约 55%。 SBERT 可用于在计算上无法用 BERT 建模的任务。例如，使用层次聚类对 10,000 个句子进行聚类需要 BERT 大约 65 小时，因为必须计算大约 5000 万个句子组合。使用 SBERT，我们能够将工作时间减少到大约 5 秒。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在语义相似度(STS)计算任务上，由于BERT模型规定，在计算相似度时，需要将两个句子同时进入模型，进行信息交互，这会造成大量的计算开销。</p>
<p>在实际应用中，比如FAQ检索，如果每一次用户查询过来，都需要和所有FAQ问答对进行比对，那么需要花费很久的时间。</p>
<p>作者提出的SBERT利用孪生网络模型的框架，将不同的句子输入到两个BERT模型中(但是这两个BERT模型是参数共享的，也可以理解为同一个BERT模型)，获取到每个句子的句子表征向量，最终获得的句子表征向量，可以用于语义相似度计算，也可以用于无监督的聚类任务。</p>
<p>对于求句子向量的策略，作者定义了三种：CLS token的输出向量，平均池化和最大值池化。</p>
<p>CLS token向量：将BERT模型中输出的CLS向量作为整句话的句向量<br>平均池化向量：将句子通过BERT模型得到的所有的字向量进行求均值操作，最终将均值向量作为整句话的句向量。<br>最大值池化向量：将句子通过BERT模型得到的所有字向量进行求最大值操作，最终将最大值向量作为整句话的句向量。</p>
<p>最后得到的结论是：平均池化策略最好，虽然效果没有BERT 直接输入两句话好，但是速度很快，而且比其他方法好，对于工业界很有价值。</p>
]]></content>
      <categories>
        <category>论文分享</category>
      </categories>
      <tags>
        <tag>BERT</tag>
        <tag>NLP</tag>
        <tag>SBERT</tag>
        <tag>STS</tag>
      </tags>
  </entry>
  <entry>
    <title>关于TF-IDF</title>
    <url>/2022/02/28/%E5%85%B3%E4%BA%8ETF-IDF/</url>
    <content><![CDATA[<h1 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h1><p>TF-IDF(term frequency-inverse document frequency)用于信息检索和数据挖掘的常用加权技术. TF是词频, IDF是逆文本指数</p>
<p>用于评估一个字词对于一个文件集或一个语料库中的其中一份文档的重要程度, 用作搜索信息检索, 文本挖掘和用户建模的加权因子.</p>
<span id="more"></span>
<p>搜索引擎经常使用tf-idf加权方案的变体作为在给定用户查询的情况下对文档的相关性进行评分和排序的中心工具。tf-idf可以成功地用于各种主题领域的停用词过滤，包括文本摘要和分类。</p>
<p>还有一种重要的说法是<strong>为了把查询关键字（Query）和文档（Document）都转换成 “向量”，并且尝试用线性代数等数学工具来解决信息检索问题, 引入了TF-IDF</strong></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h1><p>如果某个词或者短语在一篇文章中出现的频率TF高, 而在其他文章中很少出现, 那么则认为此词或者短语具有很好的类别区分能力.</p>
<p>字词的重要程度随着它在文件中出现的次数成正比增加, 但同时会随着它在语料库中出现的频率成反比下降.</p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h1><h2 id="计算某个特定的词w在该文章的TF-IDF"><a href="#计算某个特定的词w在该文章的TF-IDF" class="headerlink" title="计算某个特定的词w在该文章的TF-IDF"></a>计算某个特定的词w在该文章的TF-IDF</h2><p>计算词频</p>
<script type="math/tex; mode=display">词频=某个词在文章中出现的次数</script><p>考虑到文章有长短之分,为了便于不同文章的比较, 进行词频标准化</p>
<script type="math/tex; mode=display">词频= \frac {某个词在文章中的出现次数}{文章中的总词数}</script><script type="math/tex; mode=display">TF_w= \frac {N_w}{N}</script><p>其中Nw是某一文本中词条w出现的次数, N是该文本总词条数</p>
<h2 id="计算逆文本频率"><a href="#计算逆文本频率" class="headerlink" title="计算逆文本频率"></a>计算逆文本频率</h2><script type="math/tex; mode=display">逆文本频率=log(\frac{语料库的文档总数}{包含该词的文档数+1})</script><p>如果一个词越常见, 那么分母越大, 逆文档频率就越小, 越接近0.<br>分母之所以要+1, 是为了避免分母为0.</p>
<script type="math/tex; mode=display">IDF_w=log(\frac {Y}{Y_w+1})</script><p>其中Y是语料库的文档总数, Yw是包含词条w的文档数</p>
<h2 id="计算TF-IDF"><a href="#计算TF-IDF" class="headerlink" title="计算TF-IDF"></a>计算TF-IDF</h2><script type="math/tex; mode=display">TF-IDF_w=TF_w*IDF_w</script><p>从以上计算公式就可以看出, 某一特定文件的高词语频率, 以及该词语在整个文件集合中的低文件频率, 可以产生高权重的TF-IDF</p>
<h2 id="代码实现便于理解"><a href="#代码实现便于理解" class="headerlink" title="代码实现便于理解"></a>代码实现便于理解</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先进行词频统计, 再转化为TF-IDF矩阵</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer  </span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer  </span><br><span class="line"><span class="comment"># corpus 模拟语料库</span></span><br><span class="line">corpus=[<span class="string">&quot;second third document&quot;</span>,</span><br><span class="line">        <span class="string">&quot;second second document&quot;</span>]</span><br><span class="line">tfvectorizer=CountVectorizer() </span><br><span class="line">count_vector=tfvectorizer.fit_transform(corpus) <span class="comment"># Tf 矩阵</span></span><br><span class="line">transformer = TfidfTransformer() <span class="comment"># 转换Tf矩阵</span></span><br><span class="line">tfidf = transformer.fit_transform(count_vector) <span class="comment"># 将TF转换成Tf-Idf</span></span><br><span class="line">arr=tfidf.toarray()</span><br></pre></td></tr></table></figure>
<p>那么这两个文件就可以使用下面两个向量来表示</p>
<p><img src="https://upload-images.jianshu.io/upload_images/15198150-82a3c4c9e23b8540.png?imageMogr2/auto-orient/strip|imageView2/2/w/403/format/webp" alt=""></p>
<h1 id="4大常见变种"><a href="#4大常见变种" class="headerlink" title="4大常见变种"></a>4大常见变种</h1><h2 id="对数函数变换避免TF线性增长"><a href="#对数函数变换避免TF线性增长" class="headerlink" title="对数函数变换避免TF线性增长"></a>对数函数变换避免TF线性增长</h2><p>很多人注意到 TF 的值在原始的定义中没有任何上限。虽然我们一般认为一个文档包含查询关键词多次相对来说表达了某种相关度，但这样的关系很难说是线性的。文档 A 可能包含 “Car” 这个词 100 次，而文档 B 可能包含 200 次，是不是说文档 B 的相关度就是文档 A 的 2 倍呢？其实，很多人意识到，超过了某个阈值之后，这个 TF 也就没那么有区分度了。</p>
<p><strong>用 Log，也就是对数函数，对 TF 进行变换，就是一个不让 TF 线性增长的技巧</strong>。具体来说，人们常常用 1+Log(TF) 这个值来代替原来的 TF 取值。在这样新的计算下，假设 “Car” 出现一次，新的值是 1，出现 100 次，新的值是 5.6，而出现 200 次，新的值是 6.3。很明显，这样的计算保持了一个平衡，既有区分度，但也不至于完全线性增长。</p>
<h2 id="对TF标准化解决长短文档问题"><a href="#对TF标准化解决长短文档问题" class="headerlink" title="对TF标准化解决长短文档问题"></a>对TF标准化解决长短文档问题</h2><p>经典的计算并没有考虑 “长文档” 和“短文档”的区别。一个文档 A 有 3,000 个单词，一个文档 B 有 250 个单词，很明显，即便 “Car” 在这两个文档中都同样出现过 20 次，也不能说这两个文档都同等相关。<strong>对 TF 进行 “标准化”（Normalization），特别是根据文档的最大 TF 值进行的标准化，成了另外一个比较常用的技巧</strong>。</p>
<h2 id="对数函数处理IDF解决线性增长问题"><a href="#对数函数处理IDF解决线性增长问题" class="headerlink" title="对数函数处理IDF解决线性增长问题"></a>对数函数处理IDF解决线性增长问题</h2><p><strong>第三个常用的技巧，也是利用了对数函数进行变换的，是对 IDF 进行处理</strong>。相对于直接使用 IDF 来作为 “惩罚因素”，我们可以使用 N+1 然后除以 DF 作为一个新的 DF 的倒数，并且再在这个基础上通过一个对数变化。这里的 N 是所有文档的总数。这样做的好处就是，第一，使用了文档总数来做标准化，很类似上面提到的标准化的思路；第二，利用对数来达到非线性增长的目的。</p>
<h2 id="查询词以及文档向量标准化"><a href="#查询词以及文档向量标准化" class="headerlink" title="查询词以及文档向量标准化"></a>查询词以及文档向量标准化</h2><p>还有一个重要的 TF-IDF 变种，则是对查询关键字向量，以及文档向量进行标准化，使得这些向量能够不受向量里有效元素多少的影响，也就是不同的文档可能有不同的长度。在线性代数里，可以把向量都标准化为一个单位向量的长度。这个时候再进行点积运算，就相当于在原来的向量上进行余弦相似度的运算。所以，另外一个角度利用这个规则就是直接在多数时候进行余弦相似度运算，以代替点积运算。</p>
<h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><p>1971 年，美国康奈尔大学教授杰拉德 · 索尔顿（Gerard Salton）发表了《SMART 检索系统：自动文档处理实验》（The SMART Retrieval System—Experiments in Automatic Document Processing）一文，文中首次提到了把查询关键字和文档都转换成 “向量”，并且给这些向量中的元素赋予不同的值。这篇论文中描述的 SMART 检索系统，特别是其中对 TF-IDF 及其变种的描述成了后续很多工业级系统的重要参考。</p>
<p>1972 年，英国的计算机科学家卡伦 · 琼斯（Karen Spärck Jones）在《从统计的观点看词的特殊性及其在文档检索中的应用》（A Statistical Interpretation of Term Specificity and Its Application in Retrieval） 一文中第一次详细地阐述了 IDF 的应用。其后卡伦又在《检索目录中的词赋值权重》（Index Term Weighting）一文中对 TF 和 IDF 的结合进行了论述。可以说，卡伦是第一位从理论上对 TF-IDF 进行完整论证的计算机科学家，因此后世也有很多人把 TF-IDF 的发明归结于卡伦。</p>
<p>杰拉德本人被认为是 “信息检索之父”。他 1927 年出生于德国的纽伦堡，并与 1950 年和 1952 年先后从纽约的布鲁克林学院获得数学学士和硕士学位，1958 年从哈佛大学获得应用数学博士学位，之后来到康奈尔大学参与组建计算机系。为了致敬杰拉德本人对现代信息检索技术的卓越贡献，现在，美国计算机协会 ACM（Association of Computing Machinery）每三年颁发一次“杰拉德 · 索尔顿奖”（Gerard Salton Award），用于表彰对信息检索技术有突出贡献的研究人员。卡伦 · 琼斯在 1988 年获得了第二届“杰拉德 · 索尔顿奖” 的殊荣。</p>
<h1 id="思考与不足"><a href="#思考与不足" class="headerlink" title="思考与不足"></a>思考与不足</h1><p>TF-IDF算法主要适用于英文,中文首先要进行分词, 分词后要解决多词一义, 一次多义的问题.<br>这两个问题不能通过TF-IDF方法很好的解决.<br>于是就有了后来的词嵌入方法, 用向量表示一个词.</p>
<p>后续会继续更新有关TF-IDF</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/091383e86825">Tf-Idf详解及应用 - 简书</a><br><a href="https://easyai.tech/ai-definition/tf-idf/">一文看懂 TF-IDF (概念图解+4大变种+发展历史)</a></p>
<p>未看<br><a href="https://www.cnblogs.com/geeks-reign/p/TF-IDF.html">经典文本特征表示方法: TF-IDF - geeks_reign - 博客园</a></p>
]]></content>
      <categories>
        <category>知识整理</category>
      </categories>
      <tags>
        <tag>IR</tag>
        <tag>NLP</tag>
        <tag>ML</tag>
        <tag>TF-IDF</tag>
      </tags>
  </entry>
</search>
