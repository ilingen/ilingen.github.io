<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ilingen.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="最近在准备毕设，需要用到Sentence-BERT，所以找来论文进行了一次精读，下面主要为原文翻译和我的一些注释。 原论文链接在这 论文提供的代码在这 中文SBERT使用和微调博客在这">
<meta property="og:type" content="article">
<meta property="og:title" content="Sentence-BERT论文分享">
<meta property="og:url" content="https://ilingen.github.io/2022/03/cl0qsofk20009k4vnbgzqgb6n/d784dbf69967/index.html">
<meta property="og:site_name" content="ilingen">
<meta property="og:description" content="最近在准备毕设，需要用到Sentence-BERT，所以找来论文进行了一次精读，下面主要为原文翻译和我的一些注释。 原论文链接在这 论文提供的代码在这 中文SBERT使用和微调博客在这">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/g45s1xCRrLQDIXn.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/9PGDo86ihdYaEOq.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/6Zb2kWGjYNu1DgQ.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/1E8ezr2Jt3N4IkY.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/CwYXkEKrP8D4Ni1.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/pkoXxtwjsfAR1rU.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/6MTHlbmqCdeRQyK.png">
<meta property="og:image" content="https://s2.loli.net/2022/03/02/dC9VXthcNMZiu2q.png">
<meta property="article:published_time" content="2022-03-02T09:32:33.000Z">
<meta property="article:modified_time" content="2022-03-14T08:20:47.116Z">
<meta property="article:author" content="ilingen">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="SBERT">
<meta property="article:tag" content="STS">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/03/02/g45s1xCRrLQDIXn.png">

<link rel="canonical" href="https://ilingen.github.io/2022/03/cl0qsofk20009k4vnbgzqgb6n/d784dbf69967/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Sentence-BERT论文分享 | ilingen</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="ilingen" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ilingen</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">曾许人间第一流</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ilingen.github.io/2022/03/cl0qsofk20009k4vnbgzqgb6n/d784dbf69967/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="ilingen">
      <meta itemprop="description" content="A Rookie'blog in NLP&IR">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ilingen">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Sentence-BERT论文分享
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-02 17:32:33" itemprop="dateCreated datePublished" datetime="2022-03-02T17:32:33+08:00">2022-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-03-14 16:20:47" itemprop="dateModified" datetime="2022-03-14T16:20:47+08:00">2022-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" itemprop="url" rel="index"><span itemprop="name">论文分享</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>最近在准备毕设，需要用到Sentence-BERT，所以找来论文进行了一次精读，下面主要为原文翻译和我的一些注释。</p>
<p>原论文链接<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.10084">在这</a></p>
<p>论文提供的代码<a target="_blank" rel="noopener" href="https://github.com/UKPLab/sentence-transformers">在这</a></p>
<p>中文SBERT使用和微调博客在这</p>
<span id="more"></span>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>BERT和RoBERTa在<strong>语义文本相似性(semantic textual similarity, STS)</strong>等句子对(sentence-pair)回归任务上有SOTA的表现。然而，这需要两个句子都输入到网络中，这会造成巨大的计算开销。</p>
<blockquote>
<p>在10000个句子的集合中找到最相似的句子对需要使用BERT进行大约50000w词推理计算(65小时)。BERT的构造使得它不适合用于语义相似性搜索以及聚类等无监督任务。</p>
</blockquote>
<p>我们提出了Sentence-BERT（SBERT），这是对预训练的BERT网络的一种修改，它使用<strong>siamese和triplet(三重网络)结构来推导语义上有意义的句子嵌入，可以使用余弦相似性进行比较。这减少了寻找最相似配对的工作量，从使用BERT/RoBERTa的65小时减少到使用SBERT的约5秒，同时保持了使用BERT的准确性。</strong><br>我们评估了SBERT和SRoBERTa在常见STS任务和迁移学习任务中的表现，其表现优于其他最先进的句子嵌入方法。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Sentence-BERT是对BERT网络的一种修改，使用siamese和三元组网络(triplet networks)，能够导出语义上有意义的句子嵌入(sentence-embedding)。</p>
<blockquote>
<p> 这里表明SBERT只是对BERT网络的一种修改，而且从后面也能看到不是涉及到结构内部的修改，是对训练方式和外接一层网络的改动。</p>
<p> 这里的<strong>句子嵌入是指语义上相似的句子在向量空间相近，和word-embedding类似。</strong></p>
</blockquote>
<p>这使得SBERT能够用于BERT还不适用的任务。包含<strong>大规模的语义相似性对比，聚类和通过语义搜索进行信息检索。</strong></p>
<p>BERT在各种句子分类和句子对回归任务上取得了SOTA的表现，使用交叉编码器(cross-encoder)：将两句话传递到transformer网络并且预测目标值。然而，由于句子的组合太多，这些设置不适合各种<strong>成对回归任务</strong>(various pair regression)。</p>
<blockquote>
<p>BERT只接受两个句子的输入，而且每次需要经过BERT内部网络运算后才能得到相似度，所以对于大型任务，开销很大。</p>
</blockquote>
<p>在n=10000的句子的集合中，找到最相似的句子需要BERT进行<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="24.336ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10756.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(822.2,0)"><path data-c="B7" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(1322.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1711.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2533.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(3533.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4033.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4422.9,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mn" transform="translate(4922.9,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(5700.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(6756.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1000,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(1500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(2000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(2500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(3000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(3500,0)"></path></g></g></g></svg></mjx-container>次推理计算。需要大约65h。</p>
<p>研究聚类和语义搜索问题的一种常见方法是将每个句子映射到向量空间，这样语义相似的句子就很接近了。</p>
<p>使用BERT做句子嵌入有两种方式：<strong>平均BERT输出层(BERT 嵌入)或使用第一个[CLS] token的输出。但是这种常见的作法会产生相当糟糕的句子嵌入，比[[GLoVe]]的嵌入更糟糕。</strong></p>
<p>为了缓解这个问题，我们开发了SBERT, (siamese network)孪生网络体系结构获得固定长度句子向量表示。使用相似性度量，如余弦相似性或曼哈登/欧氏距离，可以找到语义相似的句子。这些相似性度量可以在现代硬件上非常高效地执行，从而允许SBERT用于语义相似性搜索以及聚类。<br>我们在NLI数据集上对SBERT进行微调，SBERT在STS任务上性能提升显著。</p>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>BERT为各种NLP任务设定了最新的SOTA结果，包括问答(question answering)、句子分类(sentence classification)和句子对回归(sentence-pair regression)。<br>用于句子对回归的BERT输入由两个句子组成，由一个特殊的[SEP]标记分隔。应用超过12层（基本模型）或24层（大模型）的多头注意力机制，并将输出传递到一个简单的回归函数，以导出最终标签。在STS任务上取得了SOTA的结构(Cer,2017)<br>RoBERTa表明，通过对训练前进行一些小的调整，可以进一步提高BERT的表现(Liu 2019)。</p>
<blockquote>
<p>BERT网络结构的一个大缺点是不能计算独立的句子嵌入，这使得从BERT导出单个句子嵌入变得困难。</p>
</blockquote>
<p>为了绕过这个限制，研究人员通过BERT传递单个句子，然后通过<strong>平均输出(类似于平均单词嵌入)或使用特殊CLS标记的输出，得到一个固定大小的向量</strong>。</p>
<p>句子嵌入是一个被广泛研究的领域，提出了几十种方法。<br>Skip-Thought训练一种编码器-解码器架构来预测周围的句子。<br>InferSent使用SNLI斯坦福自然语言推理数据集合多类型NLI数据集的标记数据来训练孪生BiLSTM网络，在输出上进行最大池化。优于SkipThought等无监督方法。<br>Universal Sentence Encoder训练一个transformer的网络，并通过SNLI训练增强无监督学习。<br>Hill等人表明，句子嵌入训练的任务显著影响他们的质量。<br>之前的研究发现SNLI数据集适合训练句子嵌入。<br>Yang等人提出了一种使用孪生DAN和孪生transformer网络，从Reddit上进行对话训练，该方法在STS基准数据集上取得了良好的效果。<br>Humeau讨论了BERT的交叉编码器的运行是开销，并提出了一种方法(poly-encoders，多编码器)来计算m个上下文向量和预先计算的候选嵌入之间的分数。这个方法适合在更大的集合中找到得分更高的句子。然而，多编码器的缺点是得分函数不对称，并且计算开销对于聚类等用例来说太大，需要<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="5.832ex" height="2.452ex" role="img" focusable="false" viewBox="0 -833.9 2577.6 1083.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(1152,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(633,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2188.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>得分计算。</p>
<p>以前的神经网络句子嵌入方法是从随机初始化开始训练的。<br>在本论文中，<strong>我们使用预先训练的BERT和RoBERTa网络，并仅对其做微调，以生成有用的句子嵌入</strong>，这大大减少了所需的训练时间。</p>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>SBERT在BERT/RoBERTa的输出中添加了一个<strong>池化</strong>操作，以导出固定大小的句子嵌入。我们实现了三种池化策略：<strong>使用CLS-token的输出，计算所有输出向量的平均值(MEAN-strategy)，计算输出向量随时间的最大值(MAX-strategy)。默认配置是MEAN。</strong></p>
<p>为了优化BERT/RoBERTa，我们创建了孪生网络和三元组网络，以更新权重，从而使生成的句子嵌入具有语义信息，并且可以通过余弦相似性进行比较。</p>
<blockquote>
<p>BERT产生的句向量不能通过余弦相似性比较，余弦相似性默认所有维度的权重是一样的，而BERT的语句嵌入在不同维度上的权重不同。</p>
<p>作者在对BERT模型进行微调时，设置了三个目标函数，用于不同任务的训练</p>
</blockquote>
<p>我们在以下架构和目标函数进行实验。</p>
<ul>
<li><strong>Classification Objective Function</strong><br>我们把sentence embeddings u和v以及其位差(element-wise difference)|u-v|进行拼接，并将其乘上一个可训练的权重<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="11.41ex" height="2.288ex" role="img" focusable="false" viewBox="0 -853.7 5043.2 1011.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1560,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2504.8,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1100,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1878,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></g></g></svg></mjx-container><script type="math/tex; mode=display">o=softmax(W_t(u, v, |u-v|)</script>n是sentence embedding的维度，k是类别的数量。<br>使用交叉熵作为优化。</li>
<li><strong>Regression Objective Function</strong><br>计算sentence embeddings u和v的余弦相似性，使用均方误差损失作为目标函数。</li>
<li><strong>Triplet Objective Function</strong><br>给定一个锚定句a，一个肯定句p和一个否定句n，Triplet损失调整网络，使得a和p之间的距离小于a和n之间的距离。<br>最小化以下损失函数<script type="math/tex; mode=display">max(||s_a-s_p||-||s_a-s_n||+\epsilon, 0)</script><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.164ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 956.5 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container>是a,n,p的sentence embedding，|| · ||为距离度量和margin ε。<br>Margin ε确保<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex" xmlns="http://www.w3.org/2000/svg" width="2.054ex" height="1.65ex" role="img" focusable="false" viewBox="0 -442 907.7 729.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex" xmlns="http://www.w3.org/2000/svg" width="2.095ex" height="1.355ex" role="img" focusable="false" viewBox="0 -442 926.1 599.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></svg></mjx-container>之间的距离要比<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.209ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 976.3 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex" xmlns="http://www.w3.org/2000/svg" width="2.095ex" height="1.355ex" role="img" focusable="false" viewBox="0 -442 926.1 599.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g></g></svg></mjx-container>的距离至少近ε。<br>我们使用欧氏距离作为距离度量并且设置ε=1。<br><img src="https://s2.loli.net/2022/03/02/g45s1xCRrLQDIXn.png" alt=""><h2 id="Training-Details"><a href="#Training-Details" class="headerlink" title="Training Details"></a>Training Details</h2>我们在 <strong>SNLI (Bowman et al., 2015) 和 Multi-Genre NLI (Williams et al., 2018) 数据集的组合上训练 SBERT。</strong> SNLI 是 570,000 个句子对的集合，标注了矛盾、eintailment 和中性标签。 MultiNLI 包含 430,000 个句子对，涵盖了各种类型的口语和书面文本。 我们使用一个 epoch 的 3 路 softmaxclassifier 目标函数对 SBERT 进行微调。 我们使用了 16 的批量大小、学习率为 2e-5 的 Adam 优化器，以及超过 10% 的训练数据的线性学习率热身。 我们的默认池化策略是 MEAN。<h1 id="Evaluation-Semantic-Textual-Similarity"><a href="#Evaluation-Semantic-Textual-Similarity" class="headerlink" title="Evaluation-Semantic Textual Similarity"></a>Evaluation-Semantic Textual Similarity</h1></li>
</ul>
<p>我们评估 SBERT 在常见语义文本相似性 (STS) 任务中的性能。<strong>最先进的方法通常会学习一个（复杂的）回归函数，将sentence embedings映射到相似性分数。</strong> 然而，这些回归函数是work pair-wise的，并且由于组合爆炸，如果句子的集合达到一定的大小，这些回归函数通常是不可扩展的。 相反，<strong>我们总是使用余弦相似度来比较两个句子嵌入之间的相似度。 我们还使用负曼哈顿距离和负欧几里德距离作为相似性度量进行了实验，但所有方法的结果大致相同</strong>。</p>
<blockquote>
<p>作者提出的SBERT的语句嵌入可以通过余弦相似度进行比较，从而不需要一个回归函数将embeddings映射到分数上去。</p>
</blockquote>
<h2 id="Unsupervised-STS"><a href="#Unsupervised-STS" class="headerlink" title="Unsupervised STS"></a>Unsupervised STS</h2><p>我们在<strong>不使用任何 STS 特定训练数据的情况下直接评估 SBERT 对 STS 的性能</strong>。 我们使用 STS 任务 2012 - 2016（Agirre et al., 2012, 2013, 2014, 2015, 2016）、STS 基准（Cer et al., 2017）和 SICK-Relatedness 数据集（Marelli et al., 2014） ）。 这些数据集在句子对的语义相关性上提供了 0 到 5 之间的标签。 我们在 (Reimers et al., 2016) 中表明 Pearson 相关性非常适合 STS。 相反，我们计算句子嵌入的余弦相似度与gold标签之间的 Spearman 等级相关性。 其他句子嵌入方法的设置是等效的，相似度由余弦相似度计算。 结果如表 1 所示。<br><img src="https://s2.loli.net/2022/03/02/9PGDo86ihdYaEOq.png" alt=""><br>结果表明，直接使用BERT的输出会导致相当差的性能，平均BERT embedding嵌入实现的平均相关性仅为54.81，使用CLS  token输出为29.19的平均相关性，两者都比计算平均GloVe嵌入差。<br>使用所描述的孪生网络结构和微调机制显著改善了相关性，大大优于InferSent和通Universal Sentence Encoder。SBERT的表现比Universal Sentence Encoder差的唯一数据集是SICK-R。Universal Sentence Encoder在各种数据集上接受过培训，包括新闻、问答页面和论坛，这似乎更适合SICK-R的数据。相比之下，SBERT只在维基百科（通过BERT)和NLI数据上接受过预训练。<br>虽然RoBERTa能够提高多个监督任务的性能，当我们只观察到SBERT和SRoBERTa在生成句子嵌入方面的微小差异。</p>
<h2 id="Supervised-STS"><a href="#Supervised-STS" class="headerlink" title="Supervised STS"></a>Supervised STS</h2><p>STS 基准 (STSb)（Cer 等人，2017 年）提供了一个流行的数据集，用于评估受监督的 STS 系统。数据包括来自标题、新闻和论坛三个类别的 8,628 个句子对。它分为训练（5,749）、开发（1,500）和测试（1,379）。 BERT 通过将两个句子传递到网络并使用简单的回归方法输出，在这个数据集上设置了一个新的最先进的性能。<br>我们<strong>使用训练集和回归目标函数对 SBERT 进行微调。在预测时，我们计算句子嵌入之间的余弦相似度</strong>。所有系统都使用 10 个随机种子进行训练以对抗差异（Reimers 和 Gurevych，2018 年）。<br>结果如表 2 所示。我们试验了两种设置：仅在 STSb 上训练；首先在 NLI 上训练，然后在 STSb 上训练。我们观察到后面的策略导致 1-2 点的轻微改善。这种两步法对BERT交叉编码器的影响特别大，性能提高了3-4个百分点。我们没有观察到 BERT 和 RoBERTa 之间的显著差异。<br><img src="https://s2.loli.net/2022/03/02/6Zb2kWGjYNu1DgQ.png" style="zoom:50%;"></p>
<h2 id="Argument-Facet-Similarity-AFS语料库"><a href="#Argument-Facet-Similarity-AFS语料库" class="headerlink" title="Argument Facet Similarity (AFS语料库)"></a>Argument Facet Similarity (AFS语料库)</h2><p>我们在 Misra 等人的 Argument Facet Similarity (AFS) 语料库上评估 SBERT。 (2016)。 AFS 语料库注释了来自社交媒体对话的 6,000 个句子论据对，涉及三个有争议的话题：枪支管制、同性婚姻和死刑。数据的注释范围从 0（“不同主题”）到 5（“完全等效”）。 AFS 语料库中的相似性概念与来自 SemEval 的 STS 数据集中的相似性概念完全不同。 <strong>STS 数据通常是描述性的，而 AFS 数据是来自对话的争论性摘录。要被认为是相似的，论证不仅必须提出相似的主张，而且还必须提供相似的推理。</strong>此外，AFS 中句子之间的词汇差距要大得多。因此，简单的无监督方法以及最先进的 STS 系统在该数据集上表现不佳（Reimers 等，2019）。  </p>
<p>我们在两种情况下在此数据集上评估 SBERT：1) 正如 Misra 等人提出的那样，我们使用 10 折交叉验证评估 SBERT。这种评估设置的一个缺点是不清楚方法对不同主题的泛化程度。因此，2）我们在跨主题设置中评估 SBERT。两个主题用于训练，该方法在被遗漏的主题上进行评估。我们对所有三个主题重复此操作并平均结果。</p>
<p>SBERT 使用回归目标函数进行了微调。相似度分数是基于句子嵌入使用余弦相似度计算的。我们还提供了 Pearson 相关性 r 以使结果与 Misra 等人的结果相当。然而，我们表明（Reimers 等人，2016 年）Pearson 相关有一些严重的缺点，在比较 STS 系统时应该避免。结果如表 3 所示。<br><img src="https://s2.loli.net/2022/03/02/1E8ezr2Jt3N4IkY.png" style="zoom:50%;"><br>tf-idf、平均 GloVe 嵌入或 InferSent 等无监督方法在此数据集上的表现相当糟糕，得分较低。在 10 折交叉验证设置中训练 SBERT 的性能几乎与 BERT 相当。</p>
<p>然而，在跨主题评估中，我们观察到 SBERT 的性能下降了大约 7 个点的 Spearman 相关性。要被视为相似，论点应针对相同的主张并提供相同的推理。 <strong>BERT 能够使用注意力直接比较两个句子（例如逐字比较），而 SBERT 必须将单个句子从一个看不见的主题映射到一个向量空间，以便具有相似主张和原因的论点接近。这是一项更具挑战性的任务，它似乎需要不止两个主题来训练才能与 BERT 相提并论。</strong></p>
<h2 id="Wikipedia-Sections-Distinction"><a href="#Wikipedia-Sections-Distinction" class="headerlink" title="Wikipedia Sections Distinction"></a>Wikipedia Sections Distinction</h2><p>多尔等人 (2018) 使用维基百科为句子嵌入方法创建了一个主题细粒度的训练、开发和测试集。维基百科文章被分成不同的部分，侧重于某些方面。多尔等人假设同一部分中的句子在主题上比不同部分中的句子更接近。他们使用它来创建一个包含弱标记句子三元组的大型数据集：锚点和正例来自同一部分，而反例来自同一文章的不同部分。比如来自 Alice Arnold 的文章：Anchor：Arnold 于 1988 年加入 BBC Radio Drama 公司，正面：Arnold 于 2012 年 5 月获得媒体关注，负面：Balding 和 Arnold 都是狂热的业余高尔夫球手。<br>我们使用 Dor 等人的数据集。我们使用三元组目标，在大约 180 万个训练三元组上训练 SBERT 一个epoch，并在 222,957 个测试三元组上对其进行评估。测试三元组来自一组不同的维基百科文章。作为评估指标，<strong>我们使用准确性：正例是否比负例更接近锚点？</strong>结果如表 4 所示。<br><img src="https://s2.loli.net/2022/03/02/CwYXkEKrP8D4Ni1.png" style="zoom:50%;"><br>多尔等人使用三元组损失对 BiLSTM 架构进行了微调，以获得该数据集的句子嵌入。如表所示，SBERT 明显优于多尔等人的 BiLSTM 方法。</p>
<h1 id="Evaluation-SentEval"><a href="#Evaluation-SentEval" class="headerlink" title="Evaluation-SentEval"></a>Evaluation-SentEval</h1><p>SentEval (Conneau and Kiela, 2018) 是一种流行的工具包，用于评估句子嵌入的质量。 句子嵌入用作逻辑回归分类器的特征。 逻辑回归分类器在 10 折交叉验证设置中针对各种任务进行训练，并为测试折计算预测精度。<br><strong>SBERT 句子嵌入的目的不是用于其他任务的迁移学习。</strong>在这里，我们认为按照 Devlin 等人的描述对 BERT 进行微调。 （2018）对于新任务是更合适的方法，因为它更新了 BERT 网络的所有层。然而，SentEval 仍然可以给我们在各种任务中的句子嵌入的质量留下印象。<br>我们在以下七个 SentEval 传输任务中将 SBERT 句子嵌入与其他句子嵌入方法进行了比较：<br>• MR：电影评论片段的情感预测，从五个开始（Pang 和 Lee，2005 年）。 • CR：客户产品评论的情绪预测（Hu and Liu，2004）。 • SUBJ：来自电影评论和情节摘要的句子的主观预测（Pang 和 Lee，2004 年）。 • MPQA：来自新闻专线的短语级别意见极性分类（Wiebe 等，2005）。 • SST：带有二元标签的斯坦福情绪树库（Socher 等人，2013 年）。 • TREC：来自TREC 的细粒度问题类型分类（Li 和Roth，2002 年）。 • MRPC：来自平行新闻来源的微软研究释义语料库（Dolan 等，2004）。<br><img src="https://s2.loli.net/2022/03/02/pkoXxtwjsfAR1rU.png" alt=""><br>结果见表 5。SBERT 能够在 7 个任务中的 5 个任务中取得最佳性能。与 InferSent 和 Universal Sentence Encoder 相比，平均性能提高了大约 2 个百分点。尽管迁移学习不是 SBERT 的目的，但它在此任务上优于其他最先进的句子嵌入方法。</p>
<p>SBERT 的句子嵌入似乎很好地捕获了情感信息：与 InferSent 和 Universal Sentence Encoder 相比，我们观察到 SentEval 的所有情感任务（MR、CR 和 SST）都有很大的改进。<br>SBERT 明显比通用句子编码器差的唯一数据集是 TREC 数据集。 Universal Sentence Encoder 在问答数据上进行了预训练，这似乎有利于 TREC 数据集的问题类型分类任务。<br>平均 BERT 嵌入或使用来自 BERT 网络的 CLStoken 输出在各种 STS 任务中取得了糟糕的结果（表 1），比平均 GloVe 嵌入差。然而，对于 SentEval，平均 BERT 嵌入和 BERT CLS token输出取得了不错的结果（表 5），优于平均 GloVe 嵌入。原因是不同的设置。<strong>对于 STS 任务，我们使用余弦相似度来估计句子嵌入之间的相似度。余弦相似性平等对待所有维度。相比之下，SentEval 将逻辑回归分类器拟合到句子嵌入中。这允许某些维度对分类结果具有更高或更低的影响。</strong><br>我们得出的结论是，<strong>来自 BERT 的平均 BERT 嵌入/CLS-token 输出返回的句子嵌入不能与余弦相似度或曼哈顿/欧几里得距离一起使用。</strong><br>对于迁移学习，它们产生的结果比 InferSent 或 Universal Sentence Encoder 稍差。然而，在 NLI 数据集上使用具有 siamese 网络结构的所述微调设置产生句子嵌入，实现了 SentEval 工具包的最新技术水平。</p>
<h1 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h1><p>我们已经证明了 SBERT 句子嵌入质量。 在本节中，我们对 SBERT 的不同方面进行了消融研究，以便更好地了解它们的相对重要性。</p>
<p><strong>我们评估了不同的池化策略（MEAN、MAX 和 CLS）。 对于分类目标函数，我们评估不同的连接方法。</strong> 对于每种可能的配置，我们用 10 个不同的随机种子训练 SBERT 并平均性能。</p>
<p>目标函数（分类与回归）取决于带注释的数据集。 对于分类目标函数，我们在 SNLI 和 Multi-NLI 数据集上训练 SBERTbase。 对于回归目标函数，我们在 STS 基准数据集的训练集上进行训练。 性能是根据 STS 基准数据集的开发拆分来衡量的。 结果如表 6 所示。<br><img src="https://s2.loli.net/2022/03/02/6MTHlbmqCdeRQyK.png" style="zoom:50%;"><br>在 NLI 数据上使用分类目标函数进行训练时，池化策略的影响相当小。连接模式的影响要大得多。 InferSent (Conneau et al., 2017) 和 Universal Sentence Encoder (Cer et al., 2018) 都使用 (u, v, |u − v|, u ∗ v) 作为 softmax 分类器的输入。然而，在我们的架构中，添加元素 u ∗ v 会降低性能。</p>
<p><strong>最重要的部分是元素差异|u - v|。请注意，连接模式仅与训练 softmax 分类器相关。在推理时，在预测 STS 基准数据集的相似性时，只有句子嵌入 u 和 v 与余弦相似性结合使用。元素差异测量两个句子嵌入维度之间的距离，确保相似对更近，不同对更远。</strong></p>
<p>当用回归目标函数训练时，我们观察到池化策略有很大的影响。在那里，MAX 策略的表现明显比 MEAN 或 CLS 令牌策略差。这与 (Conneau et al., 2017) 形成对比，后者发现 InferSent 的 BiLSTM 层使用 MAX 而不是 MEAN 池化是有益的。</p>
<h1 id="Computational-Efficiency"><a href="#Computational-Efficiency" class="headerlink" title="Computational Efficiency"></a>Computational Efficiency</h1><p>句子嵌入可能需要计算数百万个句子，因此需要高计算速度。在本节中，我们将 SBERT 与平均 GloVe 嵌入、InferSent（Conneau 等人，2017 年）和 Universal Sentence Encoder（Cer 等人，2018 年）进行比较。</p>
<p>为了进行比较，我们使用 STS 基准测试中的句子（Cer 等人，2017 年）。我们使用带有 Python 字典查找和 NumPy 的简单 for 循环来计算平均 GloVe 嵌入。 InferSent4 基于 PyTorch。对于通用句子编码器，我们使用基于 TensorFlow 的 TensorFlow Hub version5。 SBERT 基于 PyTorch。为了改进句子嵌入的计算，我们实施了一种智能批处理策略：将长度相似的句子组合在一起，并仅填充到小批量中最长的元素。这大大减少了填充令牌的计算开销。</p>
<p>性能是在配备 Intel i7-5820K CPU @ 3.30GHz、Nvidia Tesla V100 GPU、CUDA 9.2 和 cuDNN 的服务器上测量的。结果如表 7 所示。<br><img src="https://s2.loli.net/2022/03/02/dC9VXthcNMZiu2q.png" alt=""><br>在 CPU 上，InferSent 比 SBERT 快 65%。 这是由于更简单的网络架构。 InferSent 使用单个 BiLSTM 层，而 BERT 使用 12 个堆叠的 Transformer 层。 然而，transformer 网络的一个优势是 GPU 上的计算效率。 在那里，具有智能批处理的 SBERT 比 InferSent 快约 9%，比 Universal Sentence Encoder 快约 55%。 智能批处理在 CPU 上实现了 89% 的加速，在 GPU 上实现了 48% 的加速。 平均手套嵌入显然是计算句子嵌入的最快方法。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>我们展示了 BERT 开箱即用地将句子映射到一个向量空间，该空间非常不适合与常见的相似性度量（如余弦相似性）一起使用。七个 STS 任务的性能低于平均 GloVe 嵌入的性能。</p>
<p>为了克服这个缺点，我们提出了 Sentence-BERT (SBERT)。 SBERT 在 siamese/triplet 网络架构中对 BERT 进行微调。我们评估了各种常见基准的质量，在那里它可以实现对最先进的句子嵌入方法的显著改进。在我们的实验中，用 RoBERTa 替换 BERT 并没有产生显著的改进。</p>
<p>SBERT 在计算上是高效的。在 GPU 上，它比 InferSent 快约 9%，比 Universal Sentence Encoder 快约 55%。 SBERT 可用于在计算上无法用 BERT 建模的任务。例如，使用层次聚类对 10,000 个句子进行聚类需要 BERT 大约 65 小时，因为必须计算大约 5000 万个句子组合。使用 SBERT，我们能够将工作时间减少到大约 5 秒。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在语义相似度(STS)计算任务上，由于BERT模型规定，在计算相似度时，需要将两个句子同时进入模型，进行信息交互，这会造成大量的计算开销。</p>
<p>在实际应用中，比如FAQ检索，如果每一次用户查询过来，都需要和所有FAQ问答对进行比对，那么需要花费很久的时间。</p>
<p>作者提出的SBERT利用孪生网络模型的框架，将不同的句子输入到两个BERT模型中(但是这两个BERT模型是参数共享的，也可以理解为同一个BERT模型)，获取到每个句子的句子表征向量，最终获得的句子表征向量，可以用于语义相似度计算，也可以用于无监督的聚类任务。</p>
<p>对于求句子向量的策略，作者定义了三种：CLS token的输出向量，平均池化和最大值池化。</p>
<p>CLS token向量：将BERT模型中输出的CLS向量作为整句话的句向量<br>平均池化向量：将句子通过BERT模型得到的所有的字向量进行求均值操作，最终将均值向量作为整句话的句向量。<br>最大值池化向量：将句子通过BERT模型得到的所有字向量进行求最大值操作，最终将最大值向量作为整句话的句向量。</p>
<p>最后得到的结论是：平均池化策略最好，虽然效果没有BERT 直接输入两句话好，但是速度很快，而且比其他方法好，对于工业界很有价值。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/BERT/" rel="tag"><i class="fa fa-tag"></i> BERT</a>
              <a href="/tags/SBERT/" rel="tag"><i class="fa fa-tag"></i> SBERT</a>
              <a href="/tags/STS/" rel="tag"><i class="fa fa-tag"></i> STS</a>
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/cl0qsofk4000dk4vn92bcb0rk/e0cb4fcc6c2c/" rel="prev" title="关于TF-IDF">
      <i class="fa fa-chevron-left"></i> 关于TF-IDF
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/cl0qsofk4000ek4vnf9eg4jya/d2d87ab21c25/" rel="next" title="关于语言模型(LM)">
      关于语言模型(LM) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Related-Work"><span class="nav-number">3.</span> <span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model"><span class="nav-number">4.</span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-Details"><span class="nav-number">4.1.</span> <span class="nav-text">Training Details</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Evaluation-Semantic-Textual-Similarity"><span class="nav-number">5.</span> <span class="nav-text">Evaluation-Semantic Textual Similarity</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Unsupervised-STS"><span class="nav-number">5.1.</span> <span class="nav-text">Unsupervised STS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Supervised-STS"><span class="nav-number">5.2.</span> <span class="nav-text">Supervised STS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Argument-Facet-Similarity-AFS%E8%AF%AD%E6%96%99%E5%BA%93"><span class="nav-number">5.3.</span> <span class="nav-text">Argument Facet Similarity (AFS语料库)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Wikipedia-Sections-Distinction"><span class="nav-number">5.4.</span> <span class="nav-text">Wikipedia Sections Distinction</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Evaluation-SentEval"><span class="nav-number">6.</span> <span class="nav-text">Evaluation-SentEval</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ablation-Study"><span class="nav-number">7.</span> <span class="nav-text">Ablation Study</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Computational-Efficiency"><span class="nav-number">8.</span> <span class="nav-text">Computational Efficiency</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">9.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">10.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ilingen"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">ilingen</p>
  <div class="site-description" itemprop="description">A Rookie'blog in NLP&IR</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ilingen" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ilingen" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liulingen429@gmail.com" title="E-Mail → mailto:liulingen429@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://www.zhihu.com/people/liu-lin-gen-77" title="zhihu → http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;liu-lin-gen-77" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/5247783364" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;5247783364" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ilingen</span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->
<script>
    //   自定义邮箱审核规则
    document.body.addEventListener('click', function(e) {
        if (e.target.classList.contains('vsubmit')) {
            const email = document.querySelector('input[type=email]');
            const nick = document.querySelector('input[name=nick]');
            const reg = /^[A-Za-z0-9\u4e00-\u9fa5]+@[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)+$/;
            if (!email.value || !nick.value || !reg.test(email.value)) {
                const str = `<div class="valert text-center"><div class="vtext">请填写正确的昵称和邮箱！</div></div>`;
                const vmark = document.querySelector('.vmark');
                vmark.innerHTML = str;
                vmark.style.display = 'block';
                setTimeout(function() {
                    vmark.style.display = 'none';
                    vmark.innerHTML = '';
                }, 2500);
            }
        }
    })
</script>

<script>
    // 点击回复直接评论,官方版本点击回复时都是跳回到页面上方的评论框进行回复，评论框是固定不动的
    // 参考https://immmmm.com/valine-diy,用到jQuery
    $(document).ready(function(){
        //$('.vemoji-btn').text('😀');
        $("#vcomments").on('click', 'span.vat',function(){
            $(this).parent('div.vmeta').next("div.vcontent").after($("div.vwrap"));
            $('textarea#veditor').focus();
        })
    })
</script>
<!-- 评论框美化 -->
<style>
    #comments .veditor{
        min-height: 10rem;
        background-image: url(https://gitee.com/wugenqiang/PictureBed/raw/master/CS-Notes/20200425091751.png);
        background-size: contain;
        background-repeat: no-repeat;
        background-position: right;
        background-color: rgba(255,255,255,0);
        resize: none;}
</style>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
